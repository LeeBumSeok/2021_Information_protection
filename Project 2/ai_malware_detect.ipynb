{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdRPzSdYSAbf",
        "outputId": "7ab4726a-80d3-4bed-fbf2-749e264c5e4f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import pprint\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction import FeatureHasher\n",
        "from sklearn.feature_extraction import FeatureHasher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNVKxXs7SAbk"
      },
      "outputs": [],
      "source": [
        "SEED = 41\n",
        "\n",
        "def read_label_csv(path):\n",
        "    label_table = dict()\n",
        "    with open(path, \"r\",encoding='ISO-8859-1') as f:\n",
        "        for line in f.readlines()[1:]:\n",
        "            fname, label = line.strip().split(\",\")\n",
        "            label_table[fname] = int(label)\n",
        "    return label_table\n",
        "\n",
        "def read_json(path):\n",
        "    with open(path, \"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def load_model(**kwargs):\n",
        "    if kwargs[\"model\"] == \"rf\":\n",
        "        return RandomForestClassifier(random_state=kwargs[\"random_state\"], n_jobs=4)\n",
        "    elif kwargs[\"model\"] == \"dt\":\n",
        "        return DecisionTreeClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"lgb\":\n",
        "        return LGBMClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"svm\":\n",
        "        return SVC(random_state=kwargs[\"random_state\"], probability=True)\n",
        "    elif kwargs[\"model\"] == \"lr\":\n",
        "        return LogisticRegression(random_state=kwargs[\"random_state\"], n_jobs=-1, max_iter=25000)\n",
        "    elif kwargs[\"model\"] == \"knn\":\n",
        "        return KNeighborsClassifier(n_jobs=-1)\n",
        "    elif kwargs[\"model\"] == \"adaboost\":\n",
        "        return AdaBoostClassifier(random_state=kwargs[\"random_state\"])\n",
        "    elif kwargs[\"model\"] == \"mlp\":\n",
        "        return MLPClassifier(random_state=kwargs[\"random_state\"])\n",
        "    else:\n",
        "        print(\"Unsupported Algorithm\")\n",
        "        return None\n",
        "    \n",
        "\n",
        "def train(X_train, y_train, model):\n",
        "    '''\n",
        "        머신러닝 모델을 선택하여 학습을 진행하는 함수\n",
        "\t\n",
        "        :param X_train: 학습할 2차원 리스트 특징벡터\n",
        "        :param y_train: 학습할 1차원 리스트 레이블 벡터\n",
        "        :param model: 문자열, 선택할 머신러닝 알고리즘\n",
        "        :return: 학습된 머신러닝 모델 객체\n",
        "    '''\n",
        "    clf = load_model(model=model, random_state=SEED)\n",
        "    clf.fit(X_train, y_train)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def evaluate(X_test, y_test, model):\n",
        "    '''\n",
        "        학습된 머신러닝 모델로 검증 데이터를 검증하는 함수\n",
        "\t\n",
        "        :param X_test: 검증할 2차원 리스트 특징 벡터\n",
        "        :param y_test: 검증할 1차원 리스트 레이블 벡터\n",
        "        :param model: 학습된 머신러닝 모델 객체\n",
        "    '''\n",
        "    predict = model.predict(X_test)\n",
        "    print(f\"{model}정확도\", model.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpemrbrwSAbq"
      },
      "source": [
        "## 특징 벡터 생성 예시\n",
        "- PEMINER 정보는 모두 수치형 데이터이므로 특별히 가공을 하지 않고 사용 가능\n",
        "- EMBER, PESTUDIO 정보는 가공해서 사용해야 할 특징들이 있음 (e.g. imports, exports 등의 문자열 정보를 가지는 데이터)\n",
        "- 수치형 데이터가 아닌 데이터(범주형 데이터)를 어떻게 가공할 지가 관건 >> 인코딩 (e.g. 원핫인코딩, 레이블인코딩 등)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3rAFyogSAbz"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction import FeatureHasher\n",
        "\n",
        "class PeminerParser:\n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "    \n",
        "    def process_report(self):\n",
        "        '''\n",
        "            전체 데이터 사용        \n",
        "        '''\n",
        "        \n",
        "        self.vector = [value for _, value in sorted(self.report.items(), key=lambda x: x[0])]\n",
        "        return self.vector\n",
        "    \n",
        "\n",
        "class EmberParser:\n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "    \n",
        "    def get_histogram_info(self):\n",
        "        histogram = np.array(self.report[\"histogram\"])\n",
        "        total = histogram.sum()\n",
        "        vector = histogram / total\n",
        "        return vector.tolist()\n",
        "    \n",
        "    def get_string_info(self):\n",
        "        strings = self.report[\"strings\"]\n",
        "\n",
        "        hist_divisor = float(strings['printables']) if strings['printables'] > 0 else 1.0\n",
        "        vector = [\n",
        "            strings['numstrings'], \n",
        "            strings['avlength'], \n",
        "            strings['printables'],\n",
        "            strings['entropy'], \n",
        "            strings['paths'], \n",
        "            strings['urls'],\n",
        "            strings['registry'], \n",
        "            strings['MZ']\n",
        "        ]\n",
        "        vector += (np.asarray(strings['printabledist']) / hist_divisor).tolist()\n",
        "        return vector\n",
        "    \n",
        "    def get_general_file_info(self):\n",
        "        general = self.report[\"general\"]\n",
        "        vector = [\n",
        "            general['size'], general['vsize'], general['has_debug'], general['exports'], general['imports'],\n",
        "            general['has_relocations'], general['has_resources'], general['has_signature'], general['has_tls'],\n",
        "            general['symbols']\n",
        "        ]\n",
        "        return vector\n",
        "\n",
        "    ##############################\n",
        "    # 직접 추가한 특징 추출 함수 #   \n",
        "    ##############################\n",
        "\n",
        "    #import하는 라이브러리등 feature 해시로 추출 \n",
        "    def get_imports_info(self):\n",
        "        data = self.report[\"imports\"]\n",
        "        vector = []\n",
        "        libraries = list(set([l.lower() for l in data]))\n",
        "        vector.extend(FeatureHasher(256, input_type=\"string\").transform([libraries]).toarray()[0]) # libraries_hashed\n",
        "\n",
        "        imports = [lib.lower() + ':' + e for lib, elist in data.items() for e in elist]\n",
        "        vector.extend(FeatureHasher(1024, input_type=\"string\").transform([imports]).toarray()[0]) # imports_hashed\n",
        "\n",
        "        return vector\n",
        "\n",
        "    #악성코드의 경우 export를 많이 할것으로 예상됨\n",
        "    def get_exports_info(self):\n",
        "        exports = self.report[\"exports\"]\n",
        "        vector = []\n",
        "        vector.extend(FeatureHasher(128, input_type=\"string\").transform([exports]).toarray()[0]) # exports_hashed\n",
        "        return vector\n",
        "\n",
        "    # header의 size가 지나치게 많거나\n",
        "    # version이 잘 못 되는 등의 상황이 의심됨\n",
        "    def get_header_info(self): \n",
        "        header = self.report['header']\n",
        "        vector = [\n",
        "            header['coff']['timestamp'],\n",
        "            header['optional']['major_image_version'],\n",
        "            header['optional']['minor_image_version'],\n",
        "            header['optional']['major_linker_version'],\n",
        "            header['optional']['minor_linker_version'],\n",
        "            header['optional']['major_operating_system_version'],\n",
        "            header['optional']['major_subsystem_version'],\n",
        "            header['optional']['sizeof_code'],\n",
        "            header['optional']['sizeof_headers'],\n",
        "            header['optional']['sizeof_heap_commit'],\n",
        "        ]\n",
        "        return vector\n",
        "    \n",
        "    # 파일의 정보에서 악성파일의 경우 비정상적인 상황이 있을 확률이 높음.\n",
        "    def get_general_file_info(self):\n",
        "        general = self.report[\"general\"]\n",
        "        vector = [\n",
        "            general['size'], general['vsize'], general['has_debug'], general['exports'], general['imports'],\n",
        "            general['has_relocations'], general['has_resources'], general['has_signature'], general['has_tls'],\n",
        "            general['symbols']\n",
        "        ]\n",
        "        return vector\n",
        "\n",
        "    def process_report(self):\n",
        "        vector = []\n",
        "        vector += self.get_general_file_info()\n",
        "        vector += self.get_histogram_info()\n",
        "        vector += self.get_string_info()\n",
        "        \n",
        "        \n",
        "        '''\n",
        "            특징 추가\n",
        "        '''\n",
        "        vector += self.get_general_file_info()\n",
        "        vector += self.get_header_info()\n",
        "        vector += self.get_exports_info()\n",
        "        vector += self.get_imports_info()\n",
        "        return vector\n",
        "    \n",
        "class PestudioParser:\n",
        "\n",
        "    def __init__(self, path):\n",
        "        self.report = read_json(path)\n",
        "        self.vector = []\n",
        "\n",
        "    '''\n",
        "        사용할 특징을 선택하여 벡터화 할 것을 권장\n",
        "    '''\n",
        "    \n",
        "    # libraries의 blacklist = \"x\"인 비율\n",
        "    def get_libraries_info(self):\n",
        "        try:\n",
        "            libraries = self.report[\"image\"][\"libraries\"]\n",
        "        except KeyError:\n",
        "            return [-1]\n",
        "        if libraries == \"n/a\" or len(libraries) == 1:\n",
        "            return [0]\n",
        "        try:\n",
        "            vector = [sum(1 for i in libraries[\"library\"] if i[\"@blacklist\"] == \"x\") / len(libraries[\"library\"])]\n",
        "        except TypeError:\n",
        "            vector = [1 if libraries[\"library\"][\"@blacklist\"] == \"x\" else 0]\n",
        "        return vector\n",
        "\n",
        "    # imports의 blacklist = \"x\"인  비율\n",
        "    def get_imports_info(self):\n",
        "        try:\n",
        "            imports = self.report[\"image\"][\"imports\"]\n",
        "        except KeyError:\n",
        "            return [-1]\n",
        "        if imports == \"n/a\" or len(imports) == 1:\n",
        "            return [0]\n",
        "        try:\n",
        "            vector = [sum(1 for i in imports[\"import\"] if i[\"@blacklist\"] == \"x\") / len(imports[\"import\"])]\n",
        "        except TypeError:\n",
        "            vector = [1 if imports[\"import\"][\"@blacklist\"] == \"x\" else 0]\n",
        "        return vector\n",
        "\n",
        "    # exports의 export 요소 개수 추출\n",
        "    def get_exports_info(self):\n",
        "        try:\n",
        "            exports = self.report[\"image\"][\"exports\"]\n",
        "        except KeyError:\n",
        "            return [-1]\n",
        "        if exports == \"n/a\":\n",
        "            return [0]\n",
        "        vector = [len(exports[\"export\"])]\n",
        "        return vector\n",
        "\n",
        "    #인증서가 있으면 0 없다면 1\n",
        "    def get_certificate(self):\n",
        "      try:\n",
        "        cert = self.report['image']['certificate']\n",
        "        if cert == 'n/a':\n",
        "          return [0]\n",
        "        else:\n",
        "          return [1]\n",
        "      except:\n",
        "        return [0]\n",
        "    \n",
        "\n",
        "    \n",
        "    def process_report(self):\n",
        "\n",
        "        vector = []\n",
        "        vector += self.get_libraries_info()\n",
        "        vector += self.get_imports_info()\n",
        "        vector += self.get_exports_info()\n",
        "        vector += self.get_certificate()\n",
        "\n",
        "\n",
        "        return vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ct7xf7asnTEL"
      },
      "outputs": [],
      "source": [
        "# 파일 목록 불러오기\n",
        "file_list = os.listdir(\"/Users/bumseok/workspace/2021_Information_protection/Project 2/데이터/EMBER/학습데이터\")\n",
        "very_list = os.listdir(\"/Users/bumseok/workspace/2021_Information_protection/Project 2/데이터/EMBER/검증데이터\")\n",
        "test_list = os.listdir(\"/Users/bumseok/workspace/2021_Information_protection/Project 2/데이터/EMBER/테스트데이터\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPb9HsS4SAb2"
      },
      "source": [
        "## 학습데이터 구성\n",
        "- 특징 벡터 구성은 2차원이 되어야함 e.g.  [vector_1, vector_2, ..., vector_n]\n",
        "\n",
        "- 각 벡터는 1차원 리스트, 벡터 크기는 모두 같아야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3VFElF-KlPW"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 데이터의 특징 벡터 모음(2차원 리스트) : X\n",
        "# 데이터의 레이블 모음(1차원 리스트) : y\n",
        "X, y = [], []\n",
        "\n",
        "papa = \"/Users/bumseok/workspace/2021_Information_protection/Project 2/데이터/\"\n",
        "label_table = read_label_csv(f\"{papa}학습데이터_정답.csv\")\n",
        "X, y = [], []\n",
        "l = os.listdir('/Users/bumseok/workspace/2021_Information_protection/Project 2/데이터/EMBER/학습데이터')\n",
        "for fname in l:\n",
        "    feature_vector = []\n",
        "    label = label_table[fname.split('.')[0]]\n",
        "    for data in [\"PEMINER\", \"EMBER\"]:\n",
        "        path = f\"/Users/bumseok/workspace/2021_Information_protection/Project 2/데이터/{data}/학습데이터/{fname}\"\n",
        " \n",
        "        if data == \"PEMINER\":\n",
        "              feature_vector += PeminerParser(path).process_report()\n",
        "        else :\n",
        "              feature_vector += EmberParser(path).process_report()\n",
        "\n",
        "            # print(path)\n",
        "    X.append(feature_vector)\n",
        "    y.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_val, y_val = [], []\n",
        "l = os.listdir('/Users/bumseok/workspace/2021_Information_protection/Project 2/데이터/EMBER/검증데이터')\n",
        "label_table = read_label_csv(f\"{papa}검증데이터_정답.csv\")\n",
        "for fname in l:\n",
        "    feature_vector = []\n",
        "    label = label_table[fname.split('.')[0]]\n",
        "    for data in [\"PEMINER\", \"EMBER\"]:\n",
        "        path = f\"/Users/bumseok/workspace/2021_Information_protection/Project 2/데이터/{data}/검증데이터/{fname}\"\n",
        " \n",
        "        if data == \"PEMINER\":\n",
        "              feature_vector += PeminerParser(path).process_report()\n",
        "        else :\n",
        "              feature_vector += EmberParser(path).process_report()\n",
        "\n",
        "            # print(path)\n",
        "    X_val.append(feature_vector)\n",
        "    y_val.append(label)\n",
        "\n",
        "np.asarray(X_val).shape, np.asarray(y_val).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiaocTsNSAb7"
      },
      "source": [
        "## 학습 및 검증"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 학습\n",
        "model_name = [\"rf\", \"lgb\", \"dt\", \"svm\", \"lr\", \"knn\", \"adaboost\", \"mlp\"]\n",
        "models = []\n",
        "for model in tqdm(model_name):\n",
        "    clf = train(X, y, model)\n",
        "    models.append(clf)\n",
        "    \n",
        "# 검증\n",
        "# 실제 검증 시에는 제공한 검증데이터를 검증에 사용해야 함\n",
        "for model in tqdm(models):\n",
        "    evaluate(X_val, y_val, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiyPyVGPSAb8"
      },
      "outputs": [],
      "source": [
        "# 학습\n",
        "models = [] # 여기에 dt lgb svm lr knn adaboost mlp 추가해서 모델 설정\n",
        "for model in tqdm([\"rf\", \"lgb\"]):\n",
        "    clf = train(X, y, model)\n",
        "    models.append(clf)\n",
        "    \n",
        "# 검증\n",
        "# 실제 검증 시에는 제공한 검증데이터를 검증에 사용해야 함\n",
        "for model in tqdm(models):\n",
        "    evaluate(X_val, y_val, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViOp94FKSAb_"
      },
      "source": [
        "## 앙상블 예제"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1q0M2r_SAb_"
      },
      "outputs": [],
      "source": [
        "def ensemble_result(X, y, models):\n",
        "    '''\n",
        "        학습된 모델들의 결과를 앙상블하는 함수\n",
        "\t\n",
        "        :param X: 검증할 2차원 리스트 특징 벡터\n",
        "        :param y: 검증할 1차원 리스트 레이블 벡터\n",
        "        :param models: 1개 이상의 학습된 머신러닝 모델 객체를 가지는 1차원 리스트\n",
        "    '''\n",
        "    \n",
        "    # Soft Voting\n",
        "    # https://devkor.tistory.com/entry/Soft-Voting-%EA%B3%BC-Hard-Voting\n",
        "    predicts = []\n",
        "    for i in tqdm(range(len(X))):\n",
        "        probs = []\n",
        "        for model in models:\n",
        "            prob = model.predict_proba(X)[i][1]\n",
        "            probs.append(prob)\n",
        "        predict = 1 if np.mean(probs) >= 0.5 else 0\n",
        "        predicts.append(predict)\n",
        "        \n",
        "    print(\"정확도\", accuracy_score(y, predicts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0-seTGfSAcB"
      },
      "outputs": [],
      "source": [
        "ensemble_result(X_val, y_val, models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvqfEqTsSAcE"
      },
      "source": [
        "## 특징 선택 예제 (RFE 알고리즘 사용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXTMP0t2SAcE"
      },
      "outputs": [],
      "source": [
        "def select_feature(X, y, model):\n",
        "    '''\n",
        "        주어진 특징 벡터에서 특정 알고리즘 기반 특징 선택\n",
        "        \n",
        "        본 예제에서는 RFE 알고리즘 사용\n",
        "        https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE.fit_transform\n",
        "        \n",
        "        :param X: 검증할 2차원 리스트 특징 벡터\n",
        "        :param y: 검증할 1차원 리스트 레이블 벡터\n",
        "        :param model: 문자열, 특징 선택에 사용할 머신러닝 알고리즘\n",
        "    '''\n",
        "    \n",
        "    model = load_model(model=model, random_state=SEED)\n",
        "    rfe = RFE(estimator=model)\n",
        "    return rfe.fit_transform(X, y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_X = select_feature(X, y, \"rf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "t9LMEc0Ekpz5"
      },
      "outputs": [],
      "source": [
        "new_model = train(selected_X, y, \"rf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'shape'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/b3/cfhy0j852mz8znpnvfk2lh380000gn/T/ipykernel_3190/2616649040.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluate(selected_X, y_val, new_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "# evaluate(selected_X, y_val, new_model)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_val = np.asarray(X_val)\n",
        "# y_val = np.asarray(y_val)\n",
        "\n",
        "mode=[]\n",
        "mode.append(new_model)\n",
        "for model in mode:\n",
        "    evaluate(X_val,y_val,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "진짜ai_malware.ipynb_",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
